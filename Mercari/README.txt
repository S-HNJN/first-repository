# 프로젝트 회고 · 사고 과정 기록문  
카테고리·텍스트 기반 가격 예측 모델링과 중분류 단위 분석의 한계

---

## 0. 프로젝트 환경

- **전체 데이터 수**: 1,482,535행  
- **cate1 (대분류)**: 10개  
- **cate2 (중분류)**: 113개  
- **cate3 (소분류)**: 약 870종 (세부 상품군, 너무 잘게 나뉘어 있어 직접 단위 분석 대상에서는 제외)  
- **텍스트 컬럼**
  - `name` : 상품명  
  - `item_description` : 상품 설명  
- **목표 변수**
  - `price` (연속형, 회귀 문제)
- **주요 모델 구성**
  - 텍스트 인코딩: TF-IDF  
  - 1차(Base) 모델: Ridge, LightGBM, XGBoost  
  - 메타(Meta) 모델: LightGBM  
- **최종 성능 (전체 데이터 기반 스태킹 모델)**  
  - `R² ≈ 0.6504`  
  - `RMSE ≈ 0.4426`

> 소분류(cate3)는 약 870종으로,  
> - 단위가 지나치게 세분화되어 있고  
> - 소분류별 데이터 수가 충분하지 않은 경우가 많아  
> **모델/분석 단위를 cate3까지 떨어뜨리면 학습 안정성과 속도 모두 크게 악화될 것**이라고 판단했다.  
> 따라서 “구조적인 차이가 의미 있게 드러나는 최소 단위”를 cate2(중분류)로 설정했다.

---

## 1. 문제의 시작: “전체 상관관계 분석은 아무것도 보여주지 않았다”

처음에는 전체 데이터를 기준으로,  
`price`와 주요 수치형/파생 피처 간의 피어슨 상관관계를 계산했다.

- 결과: 대부분의 피처가 `price`와 **상관계수 0.07 이하**를 보였다.

여기서 두 가지 의문이 생겼다.

1. 정말로 이 Feature들이 가격을 거의 설명하지 못하는 걸까?  
2. 아니면 **카테고리가 다른 상품들이 한데 섞이면서**,  
   상관관계가 희석된 걸까?

이로부터 자연스럽게 다음 가설이 도출됐다.

> **“전체 단위에서는 상관이 약해 보이지만,  
> 카테고리 단위로 나누면 강한 패턴이 존재할 수도 있다.”**

---

## 2. 중분류(cate2) 단위 상관관계 재분석

위 가설을 검증하기 위해,  
데이터를 **cate2(중분류) 기준으로 그룹화**하고  
각 중분류 내부에서 `price`와 피처 간 상관관계를 다시 계산했다.

### 관찰 결과

- 전체 데이터에서는 0.07 근처에 머물던 상관계수들이,  
  **중분류 단위에서는 0.3~0.4 수준까지 올라가는 경우가 여러 개 존재**했다.
- 모든 중분류에서 같은 피처가 중요한 것은 아니었고,  
  **어떤 피처에 가격이 민감하게 반응하는지의 “패턴”이 중분류별로 달랐다.**

이때 정리한 문장은 다음과 같다.

> **“중분류별로 각 피처에 반응하는 정도와 경향이 다르게 나타난다.”**  
> **“카테고리–피처–가격 관계의 경향은, 대분류보다는 중분류 단위에서부터 뚜렷하게 드러나기 시작한다.”**

즉, **중분류(cate2)는 데이터를 의미 있게 나누기 시작하는 최소 단위**라는 인식을 갖게 되었고,  
이 인식이 이후 모델링 및 분석 전략의 출발점이 되었다.

---

## 3. 텍스트 Feature의 “진짜 영향력”에 대한 질문

중분류 단위 상관 분석을 통해,

- 텍스트 길이(len), 단어 수, 브랜드 존재 여부 등 파생 피처들이  
  어떤 중분류에서는 어느 정도 유의미하게 작동한다는 것까지는 확인할 수 있었다.

하지만 여전히 남는 핵심 질문이 있었다.

> **“`name`, `item_description`에 들어 있는 텍스트 자체가  
> 가격에 어떤 영향을 미치는지는 어떻게 정량화할 수 있을까?”**

단순 길이나 단어 수, 특수문자 여부 같은 피처만으로는  
텍스트의 “내용”을 충분히 설명하기 어렵다고 판단했고,  
텍스트를 벡터로 표현하는 방법을 찾다가 **TF-IDF**를 선택했다.

- TF-IDF로 텍스트를 벡터화하고  
- Ridge 회귀를 학습하면  
  **단어/텍스트 특성이 가격에 미치는 영향(계수)을 수치로 확인할 수 있다**고 판단했다.

---

## 4. TF-IDF + Ridge: 텍스트를 수치로 바꾸는 첫 시도

### 4.1 적용 순서

TF-IDF + Ridge는 다음 순서로 적용했다.

1. 전체 데이터 기준  
2. cate1(대분류)별  
3. cate2(중분류)별

각 단계에서:

- 텍스트를 TF-IDF 행렬로 변환  
- Ridge 회귀를 통해 `price` 예측 모델 학습  
- 단어 및 텍스트 관련 피처의 영향력(중요도/계수) 확인

### 4.2 중분류별 TF-IDF + Ridge 결과의 핵심 정량적 사실

중분류별 TF-IDF + Ridge의 Feature 중요도(혹은 계수 기반 중요도)를 분석한 결과,  
다음과 같은 패턴을 확인했다.

- **113개 중분류 중 110개에서, “브랜드 관련 피처”가 1순위 Feature**  
- **나머지 5개 중분류에서는 cate3(소분류 관련 피처)가 1순위 Feature**  
- **텍스트 길이(글자 수·단어 수)가 1순위인 중분류는 하나도 없었음**

이는 두 가지를 동시에 시사한다.

1. **브랜드 혹은 소분류 정보만으로도 가격의 상당 부분을 설명할 수 있는 중분류가 대다수**라는 점  
2. “텍스트 길이” 수준의 단순 피처는, 단독으로 1순위가 될 정도의 설명력을 갖고 있지 않다는 점

여기까지의 정리:

> **“브랜드/카테고리 정보가 이미 매우 강력하다면,  
> 텍스트 내용 자체는 추가적으로 어느 정도의 설명력을 줄 수 있을까?”**

이 질문이, 텍스트 분석(TF-IDF)과 스태킹을 “굳이” 도입하게 된 동기가 되었다.

---

## 5. 텍스트에서 브랜드·카테고리 신호 제거: 순수 텍스트 의미 추출

TF-IDF + Ridge 결과에서 상위 중요 단어들을 확인해보면,  
텍스트 안에 브랜드명 혹은 카테고리명에 해당하는 단어가 그대로 포함되는 경우가 많았다.

- 한편으로는 “모델이 브랜드/카테고리 신호를 잘 잡고 있다”는 의미이지만,
- 다른 한편으로는 “텍스트 고유 의미(문장/내용)가 어떤 영향을 미치는지 보고 싶다”는 목적에는 방해 요소였다.

그래서 다음과 같이 판단했다.

> **“브랜드/카테고리 이름 자체는 이미 별도 Feature로 존재한다.  
> 텍스트 분석에서는 이들을 제거하고,  
> 나머지 텍스트가 가격에 미치는 영향만 따로 보고 싶다.”**

이에 따라:

- 텍스트(`name`, `item_description`)에서 브랜드명 및 카테고리명에 해당하는 문자열을 제거하거나 마스킹  
- 해당 전처리된 텍스트를 다시 TF-IDF + Ridge로 학습  

이 과정을 통해  
**브랜드/카테고리 신호를 제외한 “순수 텍스트 의미”의 영향력**을 분리해서 볼 수 있게 되었고,  
이는 스스로 정의하고 해결한 Feature Engineering 시도였다.

---

## 6. 중분류별 텍스트 영향 차이 → “예측값을 Feature로 쓰자”라는 발상

브랜드/카테고리 이름을 제거한 상태에서  
중분류별 TF-IDF + Ridge를 다시 분석해 보니,

- 중분류마다 텍스트가 가격에 기여하는 방식이 서로 달랐고  
- 중요 단어 패턴 또한 중분류별로 다르게 나타났다.

여기서 다음과 같은 아이디어를 도출했다.

> **“중분류별 Ridge가 텍스트 의미를 학습했다면,  
> 그 예측값 자체를 하나의 Feature로 쓰면  
> ‘해당 중분류의 텍스트 의미’를 숫자로 요약한 Feature가 되지 않을까?”**

실제로는 다음과 같이 구현했다.

1. 중분류별 TF-IDF + Ridge 모델로 `price` 예측  
2. 예측된 가격 값을 새로운 Feature로 추가  
3. 각 Ridge 모델의 `R²`, `RMSE` 지표를 추가 Feature로 포함  
   - 의도: 해당 Ridge 모델의 신뢰도(성능)를 메타 모델에게 힌트로 제공

당시에는 이것을 단순히  
“예측값 기반 피처 + 성능 지표를 가중치 힌트로 주는 구조” 정도로 이해했지만,  
나중에 공부해보니 이 구조가 바로 **스태킹(Stacking)**의 개념과 정확히 일치한다는 것을 알게 되었다.

---

## 7. 정보 누수(Leakage) 문제 인식 → KFold OOF 도입

여기서 중요한 문제 하나를 인식했다.

- Ridge 모델은 `price`를 학습한 모델이다.  
- 이 Ridge의 예측값을 다시 train 데이터의 Feature로 사용하면,  
  “정답을 본 모델의 예측을 다시 정답 맞추는 데 사용하는 구조”가 된다.  
  → 전형적인 **정보 누수(Leakage)** 문제.

이를 해결하기 위해 **KFold Out-of-Fold(OOF)** 기법을 도입했다.

구조는 다음과 같다.

1. train 데이터를 K개의 fold로 분할 (예: 5-fold)  
2. 각 fold에 대해, 나머지 K-1개 fold로 Ridge 모델을 학습  
3. 해당 fold는 방금 학습한 모델로만 예측하여 OOF 예측값 생성  
4. 모든 fold에 대해 반복 → 전체 train 행에 대해 “자신을 학습하지 않은 모델의 예측값”을 확보

→ 이렇게 구성하면,  
**각 샘플의 Ridge 예측값은 그 샘플을 학습하지 않은 모델의 예측값**이 되고,  
정답을 모르는 상태에서 생성된 예측값을 Feature로 사용하는 구조를 만들 수 있다.

이 시점이,  
단순히 모델을 사용하는 수준을 넘어  
**모델 구조와 정보 흐름(Leakage)에 대해 고민하기 시작한 지점**이었다.

---

## 8. Meta Model로 LightGBM을 선택한 이유

메타 모델로는 **LightGBM**을 사용했다.

선택 배경은 다음과 같다.

- 초기에는 “추천이 많아서” 선택  
- 실험을 거치면서 다음과 같은 장점을 확인
  - 수치형, 카테고리형, 예측값 기반 피처 등 다양한 Feature 종류를 자연스럽게 처리  
  - 학습 속도가 빠르고, 반복 실험에 적합  
  - 비선형 상호작용을 잘 학습  
  - 스태킹 구조(여러 base 모델 예측값을 조합)에 잘 맞는 모델

결과적으로,  
**“추천이라서 썼다”에서 출발했지만,  
구조적으로도 메타 모델로 적절한 선택이었다**고 평가할 수 있었다.

---

## 9. 성능 개선 과정: 시드 vs 모델 다양성

초기 스태킹(주로 Ridge + meta LightGBM 기반) 성능은 다음과 같았다.

- `R² ≈ 0.51`  
- `RMSE ≈ 0.49`

이를 개선하기 위해 두 가지 방향을 실험했다.

### 9.1 동일 모델, 다른 시드(Seed) 앙상블

- 같은 구조의 모델에서 시드만 다르게 설정  
- 여러 번 학습한 뒤 예측값을 평균
- 기대: 랜덤성에 따른 편차 감소, 예측 안정성 향상  
- 관찰: 성능 개선 폭이 **제한적**이었다.

### 9.2 Base Model 다양성 확보

Base 모델 종류를 늘려가며 실험했다.

- Ridge (선형 모델)  
- LightGBM (트리 기반 부스팅)  
- XGBoost (또 다른 트리 기반 부스팅 알고리즘)

실험 결과:

> **“같은 모델의 시드를 여러 개 쓰는 것보다,  
> 서로 다른 모델을 조합하는 것이 훨씬 더 효과적이다.”**

각 모델이 데이터에서 포착하는 패턴이 달랐고,  
이 다양성이 메타 모델(LightGBM)이 더 우수한 조합을 학습하도록 도왔다.

최종 성능:

- `R² = 0.6504`  
- `RMSE = 0.4426`

까지 성능을 끌어올릴 수 있었다.

---

## 10. 학습 속도 문제와 CPU 코어 수에 대한 인식

중분류별 모델링(113개) × KFold(5) × 여러 Base 모델을 학습하다 보니,  
학습 속도가 매우 느려지는 문제가 발생했다.

원인 분석 과정에서 정리한 핵심은 다음과 같다.

- **LightGBM, XGBoost는 멀티코어 병렬 처리에 최적화**  
  - 코어 수가 많을수록 학습 속도가 거의 비례해서 증가  
- 사용 중인 CPU는 4코어 환경이라 병렬 처리에서 한계가 뚜렷함  
- 여기에 CatBoost까지 포함한 경우,  
  - `113개 중분류 × 5-fold × 여러 모델` = **565개 이상 모델** 학습  
  - 개인 환경에서 처리하기엔 구조적으로 과도한 연산량

이 실험을 통해 얻은 인사이트:

> **“모델링 전략을 잘못 잡으면,  
> CPU 코어 수를 아무리 늘려도 근본적인 비효율은 해결되지 않는다.”**

즉,  
**알고리즘 구조와 데이터 분할 전략이 먼저이고,  
하드웨어 스펙은 그 다음 문제**라는 점을 체감하게 되었다.

---

## 11. 전체(Global) 모델로 다시 돌아가며 깨달은 점

중분류별 모델링을 여러 차례 시도한 후,  
다시 기본적인 질문으로 돌아갔다.

> **“중분류로 나누지 않고,  
> 전체 데이터를 한 번에 쓰는 모델(TF-IDF + Ridge + LightGBM)을  
> 다시 돌려보면 어떨까?”**

전체(Global) 단위에서  
`{TF-IDF + Ridge} + LightGBM` 구조로 모델을 학습해본 결과:

- **전체 모델이 중분류별로 나눈 모델보다 성능이 더 좋았다.**  
- Feature Importance 패턴도 훨씬 안정적이었고,  
  cate2, cate3, 텍스트 기반 예측값 등이 균형 있게 작동하는 모습이었다.

이 과정에서 다음과 같은 결론에 도달했다.

1. **중분류별로 모델을 나누면, cate2는 각 모델 내부에서 상수(고정값)가 된다.**
   - 전체 모델에서는 cate2가 중요한 Feature로 작동하지만,  
   - 중분류별 모델에서는 cate2 값이 변하지 않기 때문에 정보량이 0이 된다.

2. **cate3(소분류) 역시 중분류 내부에서는 분산이 줄어들어,  
   전체 대비 변별력이 감소한다.**

3. **데이터가 113개의 부분 집합으로 쪼개지면서**
   - 각 모델의 학습 데이터 수가 줄어들고  
   - 모델의 안정성이 떨어지며  
   - 반대로 연산량과 운영 비용만 증가한다.

요약하면,

> **중분류별 모델링은, 예측 성능 관점에서  
> 가장 중요한 전역 카테고리 Feature(cate2)의 정보를  
> 스스로 제거하는 구조**였다.

---

## 12. 중분류별 모델링의 의의와 한계

### 12.1 의의 – 분석/인사이트 관점

- 중분류 단위로 피처–가격 관계를 들여다보면서,  
  **“중분류별로 각 피처에 반응하는 정도와 경향이 다르다”**는 사실을 확인  
- TF-IDF + Ridge 결과를 통해  
  중분류별로 어떤 Feature(브랜드 관련, 소분류 관련, 텍스트 기반 등)가 상대적으로 더 중요한지 비교 가능  
- 전체(Global) 모델에서는 희석될 수 있는  
  **세부 카테고리 내부의 패턴을 탐색하는 도구**로서 의미가 있었다.

### 12.2 한계 – 예측/운영 관점

- cate2 상수화 → 가장 중요한 전역 카테고리 정보 상실  
- cate3 변별력 감소  
- 데이터 파편화 → 각 모델의 학습 데이터 부족, 안정성 저하  
- 모델 수 급증 → 튜닝, 재학습, 모니터링 등 운영 관점에서 사실상 불가  
- 결과적으로 **전체(Global) 모델보다 예측 성능은 떨어지고,  
  시간·자원 비용만 크게 증가**

따라서,

> **중분류별 모델링은  
> “카테고리 내부 특성을 해석하기 위한 보조 분석”으로는 의미 있었지만,  
> 가격 예측이라는 최종 목적에서는 비효율적인 선택이었다.**

---

## 13. 이 프로젝트가 보여주는 나의 사고 방식

이 프로젝트는 단순히 “점수가 잘 나오는 모델을 만들었다”가 아니라,  
다음과 같은 사고 과정을 실제로 거친 경험이다.

1. **EDA → 이상 패턴 발견**  
   - 전체 상관관계의 한계를 인지하고,  
     “카테고리 단위로 다시 보자”는 문제의식을 가짐.

2. **가설 설정 → 검증**  
   - “경향이 중분류 단위에서부터 생기기 시작한다”는 가설을 세우고,  
     cate2 단위 상관분석 및 모델링으로 검증.

3. **텍스트의 역할에 대한 질문**  
   - “브랜드·카테고리만으로 충분한가?  
     텍스트는 어떤 추가 정보를 줄 수 있는가?”라는 질문에서 시작.

4. **TF-IDF + Ridge 도입, 브랜드/카테고리 제거라는 전처리 아이디어 적용**  
   - 텍스트에서 중복된 신호(브랜드/카테고리)를 제거하고,  
     “순수 텍스트 의미”만을 따로 보려는 Feature Engineering 시도.

5. **스스로 스태킹 구조에 도달하고, KFold OOF로 Leakage 해결**  
   - 필요에 의해 예측값을 Feature로 사용하는 구조를 설계하고,  
   - 정보 누수 문제를 인식한 뒤 KFold OOF로 이를 해결.  
   - 이후에야 이것이 스태킹 기법이라는 것을 인지.

6. **중분류별 모델링이라는 복잡한 전략을 실제 구현 후,  
   구조적 한계를 스스로 규명**  
   - cate2 상수화, 데이터 파편화, 연산량 폭증, 운영 불가 등 한계를 직접 정리.

7. **결국 전체(Global) 모델이 본질적으로 더 합리적이라는 결론 도출**  
   - “카테고리별 패턴 차이”는  
     모델을 쪼개야 한다는 근거가 아니라,  
     **카테고리 Feature 설계를 더 잘 해야 한다는 근거**라는 점을 이해.

---

## 14. 한 문장 요약

> **중분류별 패턴 차이를 실제 데이터로 확인하고,  
> 그 인사이트를 바탕으로 중분류별 모델링까지 시도해 본 끝에,  
> 예측 목적에서는 전체 모델 + 적절한 카테고리·텍스트 Feature 설계가  
> 가장 합리적이라는 결론에 도달했다.  
> 이 과정에서 EDA → 가설 → 실험 → 구조적 한계 인식 → 개선으로 이어지는  
> 데이터 분석가의 사고 사이클 전체를 한 번 완주했다.**
