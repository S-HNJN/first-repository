[프로젝트 회고 · 사고 과정 기록문]
0. 프로젝트 환경
전체 데이터: 1,482,535행
cate1(대분류): 10개
cate2(중분류): 113개
cate3(소분류): 더 세부적인 상품군
텍스트: 상품 이름(name), 제품설명(description)
목표: price 예측
사용 모델: TF-IDF + Ridge, LightGBM, XGBoost (+ meta LightGBM)
최종 성능: R² ≈ 0.6504, RMSE ≈ 0.4426

1. 문제의 시작: “전체 상관관계 분석은 아무것도 보여주지 않았다”

처음 전체 데이터에서 가격과 각 Feature 간의 상관관계를 살펴보았을 때,
거의 모든 Feature의 상관계수가 0.07 이하에 불과했다.
  
그 순간 두 가지 의문이 생겼다.
“정말로 이 Feature들이 가격을 설명하지 못하는 걸까?”
“아니면 ‘전체로 섞여 있어서’ 상관관계가 희석된 걸까?”

즉, 전체 단위에서는 상관이 약한데, 세부 단위에서는 강한 패턴이 있지 않을까?
라는 가설이 자연스럽게 생겼다.

2. 중분류(cate2) 단위로 상관관계를 다시 계산해보기
그래서 cate2(중분류) 단위로 데이터를 나누어 상관관계를 다시 구했다.

결과는 충격적이었다.

전체에서는 상관 0.07 이하였던 Feature들이
중분류 단에서는 0.3~0.4 이상의 강한 양/음의 상관을 보이기도 했다.

특히:

어떤 중분류는 brand가 가격을 거의 결정하는 수준으로 강했고
어떤 중분류는 **설명 길이(desc_len)**나 **이름 길이(name_len)**이 더 중요했고
또 어떤 중분류에서는 **cate3(소분류)**가 가격을 지배했다

정리하면:

“전체에서는 안 보이지만, 중분류 내부에서는 패턴이 명확히 존재한다.”
“중분류별로 가격 형성 규칙이 완전히 다르다.”

이건 내게 매우 강렬한 신호로 다가왔다.

3. 자연스럽게 생긴 질문

“그렇다면 가격 예측 모델도 중분류별로 따로 만들면 더 잘 맞추지 않을까?”

이 생각은 아주 자연스러운 논리적 확장이었다.

중분류별로 Feature들의 반응이 다르다는 걸 직접 확인했으니,
중분류 단위의 모델링은 오히려 정교한 접근이라고 느껴졌다.

4. 텍스트 Feature의 “진짜 영향력”을 알고 싶었다

중분류 단위에서 상관관계를 확인했을 때,
문제는 누구든 생각할 수 있는 파생 피처(brand 유무, 텍스트 길이 등)의 영향력은 금방 파악할 수 있었지만

“텍스트 자체가 가격에 어떤 영향을 주는지”는 알 수 없었다.

그래서 나는 스스로 질문했다:

“중분류별로 중요한 텍스트도 다를 텐데, 이걸 ‘점수화’할 수는 없을까?”

즉, 이름(name), 설명(item_description)의
실제 단어들이 가격에 어떤 영향을 주는지 정량화할 방법이 필요했다.

이를 분석할 수 있는 방벙에 대해 찾아봤고, TF-IDF를 알 수 있었다.

→ “아, TF-IDF로 텍스트의 영향력을 숫자로 만들 수 있겠다.”

그리고 Ridge 회귀로 TF-IDF를 학습하면
단어들의 “긍정/부정(가격에 미치는 영향의 +/–)”을 바로 확인할 수 있다는 점도 매력적이었다.

5. 그런데 문제: 중요한 단어 중 대부분이 “브랜드명/카테고리명”

TF-IDF + Ridge를 (글 전체 -> 대분류 -> 중분류 순서) 돌려보니
상위 중요 단어 중 상당 부분이:

브랜드명과 카테고리의 단어들이었다.

즉,
텍스트 특성 자체가 아니라
이미 내가 Feature로 만들어둔 값들이 텍스트에도 섞여 있는 상태였다.

그래서 다음 생각이 들었다.

“텍스트가 가진 ‘순수 의미적 영향력’을 보고 싶은데,
브랜드나 카테고리 단어가 섞여 있어 방해하고 있구나.”

그래서 브랜드/카테고리 단어들을 텍스트에서 제거하는 과정을 거쳤다.

그 후 다시 TF-IDF를 돌리니:

브랜드명이나 카테고리명 제거됨

진짜 “텍스트 의미”만의 효과를 볼 수 있게 됨

이건 스스로 발견한 의미 있는 Feature Engineering이었다.

6. 중분류별로 텍스트 영향력이 다름 → “그럼 중분류별 예측값을 Feature로 쓰자!”

중분류별로 텍스트의 영향력을 분석하다 보니
중분류마다 중요한 단어 패턴이 완전히 다르게 나타났다.

그러자 떠올랐다:

“그렇다면 중분류별 Ridge 회귀의 가격 예측값 자체를 Feature로 쓰면
그 중분류의 고유한 텍스트 의미가 ‘숫자’로 들어가는 거 아닌가?”

그래서 나는
중분류별 Ridge 가격예측 → 예측값을 Feature로 추가했다.

그리고 성능을 향상시키기 위해
R² Score와 RMSE도 Feature로 추가했다.

(당시 나는 이걸 ‘가중치 힌트 Feature’ 정도로 생각했다.
나중에야 이게 스태킹(Stacking) 기법이라는 걸 알게 된다.)

여기까지는 정말 스스로 고민해서 만들어낸 아이디어였다.

7. 하지만 문제가 있었다:
“정답(price)을 보고 학습한 모델의 예측값은 정보 누수 아닌가?”

맞다.
이건 레이블을 학습한 Ridge가 test에도 leakage를 일으키는 구조였다.

그래서 찾아보다가 KFold out-of-fold 예측값 생성 기법을 배웠다.

→ “아, 이 방식이면 정답을 모르는 상태의 예측값을 만들 수 있구나.”

즉:

train: KFold로 OOF 예측값 생성

test: 전체 모델로 예측

이걸 통해 진짜로 “정답을 모르는 상태”의 Ridge 예측 피처를 만들 수 있게 되었다.

이 깨달음은 내 ML 사고가 한 단계 올라간 지점이었다.

8. Meta Model로 LightGBM을 선택한 이유

솔직히 말하면 처음에는 “추천이라서” 썼다.
하지만 지금 와서 보면 LightGBM은 meta model로 매우 적합했다.

다양한 Feature 종류(텍스트 기반, 카테고리, 수치형)를 잘 다룸

빠르고 안정적

스태킹 구조와 궁합 좋음

복잡한 상호작용을 잘 잡음

즉, 결과적으로 매우 적절한 선택이었다.

9. 성능 개선을 위한 반복 실험

처음 meta LGBM으로 얻은 성능은 낮았다.

R² ≈ 0.51

RMSE ≈ 0.49

그래서 여러 방법을 실험했다:

(1) 시드(seed)를 바꿔서 여러 Ridge를 쌓기

현실 효과는 크지 않았다.

(2) base model 수를 늘리는 방법

Ridge

LightGBM

XGBoost

이 순서로 하나씩 추가하면서 실험했다.

여기서 놀라운 사실을 깨달았다.

“시드를 바꾸는 것보다 모델을 다양하게 하는 것이 훨씬 유효하다.”

각 base model이 잡는 패턴이 서로 달랐고
그 다양성이 meta model 성능을 밀어 올렸다.

결국 최종적인 스태킹 성능은:

R² = 0.6504

RMSE = 0.4426

까지 향상되었다.

10. 느린 속도의 원인 분석 → “CPU 코어 수의 중요성 깨달음”

중분류별 모델링을 하다 보니 모델 학습 속도가 너무 느렸다.

왜 이렇게 느릴까?

찾아보면서 다음을 배웠다:

LightGBM, XGBoost는 코어 수가 늘수록 거의 비례해서 빨라짐

내 PC CPU(7500F)는 4코어라 병렬처리에서 불리함
코어 수가 많을수록 병렬처리에서 더 유리함

CatBoost는 특히 무겁고 반복학습에 비효율적임

“113개 중분류 × 5-fold” = 565개 모델 → 개인 PC에서는 불가능한 규모

이 과정에서:

“모델링 전략을 잘못 잡으면, 코어 수를 아무리 늘려도 구조적 비효율은 해결되지 않는다.”

라는 중요한 인사이트를 얻었다.

11. 전체 모델을 다시 돌려보며 깨달은 결정적 사실

중분류별 모델링을 여러 번 해보다가
문득 이런 생각이 들었다:

“전체 단위로 TF-IDF + Ridge + LGBM만 돌리면 어떨까?”

그래서 해봤고
놀랍게도 글 전체를 분석한 모델({TF_IDF+Ridge}+LightGBM}이 이전의 초기 모델({TF_IDF+Ridge}+LightGBM}) 보다 더 성능이 좋았다.

게다가 Feature Importance도 전혀 달랐다.

이에 의문이 생겨 추가적인 학습을 했고,
그 답을 통해 핵심을 깨달았다.

→ “중분류별로 모델을 나누는 순간,

중요한 Feature(cate2)가 상수값이 되어 버린다.”

즉:

전체 모델에서는 cate2가 강력한 Feature

중분류별 모델에서는 cate2=고정값 → 정보 0

cate3도 변별력이 떨어짐

데이터도 113개로 분산 → 정보 희석

연산량은 565배 증가

결과적으로 예측 목적에는 비효율적이며 오히려 성능을 떨어뜨리는 구조였다.

12. 최종 깨달음:
“중분류별 모델링은 해석용으로는 의미 있지만,
예측 모델링 목적에서는 잘못된 선택이었다.”

중분류별 분석은 아래 목적에서는 강력한 인사이트를 제공한다:

각 중분류의 고유 패턴 이해

중분류 내부에서 브랜드/텍스트/소분류의 역할 확인

전체 모델이 놓치는 미세 패턴 탐색

하지만 가격 예측이라는 목적에서는

정보량 감소

Feature 상수화

성능 하락

관리 불가

연산량 과다

라는 한계가 명확했다.

중분류별로 패턴이 다르다는 사실을 알았다면
모델을 쪼갤 게 아니라 카테고리 Feature 자체를 강화했어야 했다.

이게 이번 프로젝트에서 얻은 가장 큰 교훈이다.

13. 전체 과정을 통해 드러난 “나의 사고 방식”

이 프로젝트는 단순히 성능을 높이는 과정을 넘어서
내가 가진 사고 방식을 그대로 드러냈다.

EDA에서 이상 패턴 발견 → 원인 탐색

가설 설정 → 직접 실험으로 검증

문제 발견 → 더 좋은 구조 탐구

스스로 스태킹 기법에 도달

데이터 분할/코어 수/정보량 같은 구조적 문제까지 파악

전체 모델 vs 부분 모델 비교로 본질적 해답 탐색

이 모든 과정은
단순히 “모델을 잘 돌리는 사람”이 아니라
문제를 구조적으로 해석하고,
실험 기반으로 개선하며,
논리적으로 결론을 도출하는 분석가라는 사실을 보여준다.

14. 마지막 요약 (한 문장 버전)

중분류별 패턴 차이를 발견한 것은 매우 중요한 인사이트였고,
이를 바탕으로 중분류별 모델링을 시도한 것은 훌륭한 탐색적 분석이었다.
그러나 가격 예측이라는 목적에서는
있는 정보를 죽이고 연산량만 늘리는 비효율적 방식이었다.
최종적으로 전체 모델 기반 스태킹 구조가 가장 합리적이며,
이번 분석 과정에서 나는 EDA → 가설 → 실험 → 구조적 이해 → 개선이라는
데이터 분석가의 사고 사이클 전체를 경험할 수 있었다.
